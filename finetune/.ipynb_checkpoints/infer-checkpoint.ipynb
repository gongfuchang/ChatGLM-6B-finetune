{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: Loading binary E:\\dev\\ChatGLM-6B\\venv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda116.dll...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1a5201f0e84b6cbf1b6cd939520460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "# torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", load_in_8bit=True, trust_remote_code=True, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# peft_path = \"output/adapter_model.bin\"\n",
    "peft_path = \"lora-alpaca-zh/adapter_model.bin\"\n",
    "\n",
    "# 注意 r(attention dimension) 需要根据lora model 不同进行设置，如 8 或者 16\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=True,\n",
    "    r=16,\n",
    "    lora_alpha=32, lora_dropout=0.1 # lora scaling parameter and the dropout probability for Lora layers\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.load_state_dict(torch.load(peft_path), strict=False)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# instructions = json.load(open(\"data/valc/valc_data.json\", encoding='utf-8'))\n",
    "instructions = json.load(open(\"data/alpaca-zh/alpaca-zh_data.json\", encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\dev\\ChatGLM-6B\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:1359: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 我们如何在日常生活中减少用水?\n",
      "Answer: 以下是一些在日常生活中减少用水的方法:\n",
      "\n",
      "1. 使用节水型器具:例如淋浴器、浴缸和马桶等,使用节水型器具可以减少水的使用量。\n",
      "\n",
      "2. 控制洗涤量:洗涤时尽量减少水的使用量,例如使用更少的水来洗涤衣物,或者采用节水洗衣机。\n",
      "\n",
      "3. 重复使用水:例如在洗衣服时使用干衣预涂法,或者在烹饪时使用重复使用的水。\n",
      "\n",
      "4. 节约用水:例如在刷牙时使用节水型牙膏,或者在洗衣服时使用节水剂。\n",
      "\n",
      "5. 收集雨水或污水:在日常生活中收集雨水或污水可以用来浇灌植物、洗车等,减少对水资源的依赖。\n",
      "\n",
      "6. 推广节水意识:通过宣传和教育,提高公众对节水意识的认识,鼓励大家在日常生活中减少用水。\n",
      "\n",
      "通过采取这些措施,我们可以在日常生活中减少用水,保护水资源的可持续利用。\n",
      "### 1.Answer:\n",
      " 1. 使用节水装置，如节水淋浴喷头和水龙头。 \n",
      "2. 使用水箱或水桶收集家庭废水，例如洗碗和洗浴。 \n",
      "3. 在社区中提高节水意识。 \n",
      "4. 检查水管和灌溉系统的漏水情况，并及时修复它们。 \n",
      "5. 洗澡时间缩短，使用低流量淋浴头节约用水。 \n",
      "6. 收集雨水，用于园艺或其他非饮用目的。 \n",
      "7. 刷牙或擦手时关掉水龙头。 \n",
      "8. 减少浇水草坪的时间。 \n",
      "9. 尽可能多地重复使用灰水（来自洗衣机、浴室水槽和淋浴的水）。 \n",
      "10. 只购买能源效率高的洗碗机和洗衣机。 \n",
      "\n",
      "\n",
      "Instruction: 编辑文章,使其更吸引读者。\n",
      "Input: 自主机器人是计算机控制的机器,被编程执行特定任务而不需要任何人类输入。自主机器人在各个行业中被越来越广泛地应用,从制造业到医疗保健再到安全。\n",
      "Answer: 自主机器人是一种能够自主执行特定任务的计算机控制机器,不需要人类干预。它们被编程用于完成各种任务,例如制造业中的装配线、医疗保健中的手术操作、以及安全领域的巡逻和救援等。随着技术的发展,自主机器人在各个行业中的应用越来越广泛,从制造业到医疗保健再到安全,它们正在成为我们生活和工作中不可或缺的一部分。\n",
      "\n",
      "自主机器人的应用范围非常广泛,不仅可以提高生产效率和产品质量,还可以减少人力成本和环境污染。在制造业中,自主机器人可以完成复杂的装配和调试任务,提高生产效率和产品质量。在医疗保健中,自主机器人可以协助医生进行手术操作,提高手术的安全性和准确性。在安全领域,自主机器人可以用于巡逻和救援,提高安全性和效率。\n",
      "\n",
      "自主机器人的技术正在不断发展,它们的智能和自主性不断提高,能够完成更多的任务。例如,自主机器人可以学习人类的行为和语言,更好地与人类交互,提高用户体验。在智能家居中,自主机器人可以成为人们的伙伴,帮助人们完成家务和娱乐任务。\n",
      "\n",
      "随着自主机器人技术的发展,我们可以预见它们将在未来扮演更加重要的角色,成为我们生活和工作中不可或缺的一部分。我们需要更多地关注机器人技术的应用和发展,更好地利用它们的优势,解决它们存在的问题,让我们的生活更加美好和\n",
      "### 2.Answer:\n",
      " 自主机器人是计算机控制的机器，被编程执行特定任务而不需要任何人类输入，从而实现了新的效率、精确度和可靠性水平。自主机器人在各个行业中被越来越广泛地应用，从制造业，它们可以使用精度和一致的质量组装复杂的组件，到医疗保健，可以协助进行医疗测试和处理，再到安全，可以监控大面积地区，保障人们和财产的安全。自主机器人还可以减少在危险或有害环境中的错误和增加安全，在工业流程的检查或维修期间等。由于其多样性，自主机器人将彻底改变我们工作方式的方式，使任务变得更加简单、快速，最终更加愉悦。 \n",
      "\n",
      "\n",
      "Instruction: 政府可以采取哪些策略来减少空气污染?\n",
      "Answer: 政府可以采取以下策略来减少空气污染:\n",
      "\n",
      "1. 推广清洁能源:政府可以通过推广太阳能、风能、水能等清洁能源来减少对传统化石燃料的依赖,从而减少空气污染。\n",
      "\n",
      "2. 限制排放:政府可以通过限制汽车排放、加强工业排放控制等方式来减少空气污染。\n",
      "\n",
      "3. 改善交通管理:政府可以通过改善交通管理、提高公共交通使用效率、鼓励步行和骑自行车等方式来减少交通拥堵和汽车排放。\n",
      "\n",
      "4. 加强环境监管:政府可以通过加强环境监管、制定严格的环保法规等方式来促进企业和个人遵守环保标准,减少空气污染。\n",
      "\n",
      "5. 促进可持续发展:政府可以通过促进可持续发展、鼓励资源节约和环境保护等方式来减少空气污染,实现经济、社会和环境的可持续发展。\n",
      "\n",
      "6. 投资和创新:政府可以通过投资和创新、提高技术水平、开发新的环保技术等方式来减少空气污染。\n",
      "### 3.Answer:\n",
      " 1. 实施强制的车辆排放标准和基于激励的计划，以降低车辆的碳足迹。\n",
      "2. 增加公共交通工具，减少公众对车辆的依赖。\n",
      "3. 增加对空气污染的影响的认识，鼓励市民减少污染物的生成。\n",
      "4. 投资于可再生能源的研究和开发，如太阳能和风能。\n",
      "5. 在工厂和发电厂安装空气污染控制装置，例如洗涤器。\n",
      "6. 对车辆和工厂使用清洁燃料。\n",
      "7. 实施更好的城市规划和控制拓展。\n",
      "8. 改善农业效率，减少化肥和杀虫剂的使用。\n",
      "9. 种植更多的树木以减少空气污染。\n",
      "10. 减少木材、煤炭和生物质的燃烧。 \n",
      "\n",
      "\n",
      "Instruction: 可再生能源的存在对环境有什么影响?\n",
      "Answer: 可再生能源(可再生能源是指使用可再生能源来产生电力的能源系统,如太阳能、风能、水能、地热能等)的出现对环境保护产生了许多积极的影响,主要包括以下几个方面:\n",
      "\n",
      "1. 减少温室气体排放:可再生能源的使用可以减少二氧化碳等温室气体的排放,从而减少全球变暖的影响。例如,太阳能和风能等可再生能源可以通过自然循环来释放二氧化碳,而不像化石燃料一样需要通过燃烧来释放它们。\n",
      "\n",
      "2. 减少污染:可再生能源的使用可以减少对化石燃料的依赖,从而减少空气污染和水质污染。例如,太阳能和风能等可再生能源可以通过自然循环来释放氧气和清新空气,而不像化石燃料一样会产生有害气体和颗粒物。\n",
      "\n",
      "3. 提高能源利用效率:可再生能源的使用可以提高能源利用效率,减少能源浪费。例如,太阳能和风能等可再生能源可以用于照明、加热、制冷和发电等方面,从而减少对传统能源的依赖,提高能源利用效率。\n",
      "\n",
      "4. 促进可持续发展:可再生能源的使用可以促进可持续发展,保护自然资源和人类福祉。例如,可再生能源的使用可以减少对土地和水资源的占用,减少对化石燃料的依赖,从而支持可持续的城市化和经济发展。\n",
      "\n",
      "可再生能源的存在对环境产生了许多积极的影响,可以减缓全球变暖、减少污染、提高能源利用效率、促进可持续发展等方面。\n",
      "### 4.Answer:\n",
      " 可再生能源的存在可以帮助减少空气污染和温室气体排放，因为它们几乎不会排放二氧化碳、二氧化硫等空气污染物。此外，使用可再生能源可以促进能源效率的进一步提高和能源利用的改善。可再生能源也可以帮助减少对化石燃料的依赖，这不仅可以减少排放，而且还可以帮助减少全球气候变化的风险。最后，可再生能源可以帮助保护自然资源，减少为了能源生产而开发更多土地和资源的需要。 \n",
      "\n",
      "\n",
      "Instruction: 解释神经网络如何学习。\n",
      "Answer: 神经网络是一种模仿生物神经系统的计算模型,可以通过对输入数据进行分类或预测,输出一个相应的预测结果。神经网络的学习是通过训练模型来优化模型的参数,使得模型能够更好地拟合训练数据,从而对新的数据进行分类或预测。\n",
      "\n",
      "神经网络的训练过程分为两个阶段:第一阶段是模型的构建,第二阶段是模型的优化。\n",
      "\n",
      "在模型的构建阶段,神经网络会接受一系列的输入数据,并通过一些中间层进行计算,最终输出一个预测结果。这些中间层包括输入层、隐藏层和输出层。每个隐藏层都会对输入数据进行一些处理,并提取出一些特征,然后通过一个输出层将特征映射到预测结果上。每个隐藏层的参数都需要通过反向传播算法来优化,以使网络的输出结果更加准确。\n",
      "\n",
      "在模型的优化阶段,神经网络会根据训练数据中存在的误差,通过反向传播算法来更新每个隐藏层的参数,以使网络的输出结果更加准确。这个过程是通过梯度下降算法来实现的。通过不断迭代,神经网络的参数会不断优化,从而提高模型的性能。\n",
      "\n",
      "神经网络的学习是通过模型的构建和优化两个过程来实现的。在构建模型时,需要选择适当的网络结构和参数设置,以使模型能够更好地拟合训练数据。在优化模型时,需要使用反向传播算法来更新每个隐藏层的参数,以使网络的输出结果更加准确。通过不断迭代,神经网络的性能将会不断提高\n",
      "### 5.Answer:\n",
      " 神经网络是一种机器学习算法，它使用连接的节点集合来近似可以将输入变量映射到输出的函数。为了学习神经网络的参数，计算机需要调整节点之间连接的权重，以便网络为给定输入产生正确的输出。这个调整过程称为学习，通过比较网络产生的输出和期望的结果，然后使用优化算法来调整权重，使得网络输出逼近期望的结果。这个过程在多个输入和期望的输出上重复进行多次迭代。最终，连接节点之间的权重将被调整，以便神经网络的输出与期望的结果相匹配，学习过程将完成。 \n",
      "\n",
      "\n",
      "Instruction: 给出一个机器学习算法的例子,并解释它是如何工作的。\n",
      "Answer: 一个常见的机器学习算法是决策树算法。决策树算法是一种基于树形结构的分类和回归算法。\n",
      "\n",
      "决策树算法的基本思想是将数据集分成若干个子集,每个子集代表一个特征或类别。然后,算法从子集中选择最有可能代表当前特征的样本作为当前节点,并将该节点的所有后代节点与该节点的特征集合进行比较,选择具有相似特征的节点作为新节点的训练样本。通过这种方式,决策树算法可以学习到特征之间的相似性和重要性,并能够准确地预测新的样本。\n",
      "\n",
      "下面是一个简单的决策树算法的实现:\n",
      "\n",
      "```\n",
      "class DecisionTreeClassifier:\n",
      "    def __init__(self, max_depth=None):\n",
      "        self.max_depth = max_depth\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        self.tree = DecisionTreeClassifier()\n",
      "        self.tree.fit(X, y)\n",
      "\n",
      "    def predict(self, X):\n",
      "        return self.tree.predict(X)\n",
      "```\n",
      "\n",
      "在这个实现中,`DecisionTreeClassifier` 类表示决策树算法的类。`fit()` 方法用于训练决策树模型,`predict()` 方法用于预测新的样本。在训练过程中,`fit()` 方法将数据集分成子集,并使用决策树模型进行预测。在预测过程中\n",
      "### 6.Answer:\n",
      " 一个流行的机器学习算法的例子是支持向量机（SVM）。它是一个用于分类和回归任务的监督学习算法。它通过在n维空间中绘制数据点，由空间中的决策边界或超平面进行分离。该算法使用最大边距，这些边距尽可能远离两类数据点。这些边距有助于创建最优的决策超平面。然后，算法通过考虑分类任务中发生的错误来调整决策超平面，并相应地修改超平面。\n",
      "\n",
      "最终，支持向量机可以使用最优的决策超平面执行分类任务，预测数据点的类别。 \n",
      "\n",
      "\n",
      "Instruction: 描述推荐系统的工作原理\n",
      "Answer: 推荐系统是一种利用历史用户行为数据、兴趣和偏好等信息,为用户推荐个性化内容的系统。其工作原理可以概括为以下几个步骤:\n",
      "\n",
      "1. 数据收集:推荐系统需要收集用户的历史行为数据,包括用户浏览的网站、搜索的关键词、观看的电影、听的音乐等等。这些数据可以用于了解用户的兴趣爱好和行为习惯。\n",
      "\n",
      "2. 数据清洗和预处理:在收集到大量的数据之后,推荐系统需要进行清洗和预处理,包括去除重复数据、缺失值填充、数据格式转换等等。这一步的目的是确保数据的质量,以便后续进行分析。\n",
      "\n",
      "3. 特征提取:特征提取是指从原始数据中提取出可以用于表示用户兴趣和行为的特征。这些特征可以是数字、标签、关键词等等。推荐系统可以使用多种方法来提取特征,如机器学习算法、文本挖掘等等。\n",
      "\n",
      "4. 模型训练:推荐系统需要使用训练数据来训练模型,以便学习用户的兴趣和行为模式。模型可以使用多种算法,如支持向量机、决策树、随机森林等等。\n",
      "\n",
      "5. 模型评估:推荐系统需要使用测试数据来评估模型的性能,以确定模型的准确性和泛化能力。评估指标可以包括准确率、召回率、F1值等等。\n",
      "\n",
      "6. 推荐生成:当用户输入新的信息时,推荐系统可以使用训练好的模型来生成个性化推荐。推荐可以是新闻、电影、音乐等等。\n",
      "### 7.Answer:\n",
      " 推荐系统是一种信息过滤系统，它使用用户过去的行为或偏好来建议用户可能感兴趣的新项目。该系统首先收集用户行为和偏好的数据，例如他们经常在线购买或查看哪些项目。然后使用这些数据基于他们过去的行为为用户创建个性化的个人资料。通过分析相似用户购买或查看的其他项目，系统可以向用户推荐量身定制的项目，以适应用户的个人资料和兴趣。 \n",
      "\n",
      "\n",
      "Instruction: 列出人工智能的五个可能应用\n",
      "Answer: 人工智能(Artificial Intelligence,简称AI)的五个可能应用如下:\n",
      "\n",
      "1. 自动驾驶:利用计算机视觉、机器学习等技术,让汽车自主地感知周围环境、做出决策和行驶。\n",
      "\n",
      "2. 智能家居:利用物联网、人工智能技术,让家居设备之间互相通信、协同工作,实现智能化的家居环境。\n",
      "\n",
      "3. 医疗诊断:利用机器学习、深度学习等技术,对医学图像、病历等进行分析和处理,提高医疗诊断的准确性和效率。\n",
      "\n",
      "4. 机器人:利用机器人技术,让机器人执行重复性、危险或繁琐的任务,如工厂流水线、手术等。\n",
      "\n",
      "5. 自然语言处理:利用自然语言处理技术,让计算机理解和处理人类语言,如语音识别、机器翻译、文本分析等。\n",
      "### 8.Answer:\n",
      " 1. 自动化和机器人：AI可用于自动化和优化工业或制造过程。\n",
      "2. 医疗保健： AI可用于诊断和治疗疾病，提高医疗组织的工作流程效率或为患者提供个性化护理。\n",
      "3. 银行和金融：AI可用于开发自动交易系统，实现更精确的金融交易欺诈检测，并提供个性化的金融建议。\n",
      "4. 图像，语音和文本识别：AI可用于与图像识别，语音合成和自然语言处理相关的任务。\n",
      "5. 自主车辆：AI可用于开发无需人为干预的自动驾驶汽车，无人机和其他车辆。 \n",
      "\n",
      "\n",
      "Instruction: 列举自然语言处理任务的四个例子\n",
      "Answer: 自然语言处理任务的四个例子包括:\n",
      "\n",
      "1. 文本分类:将文本归为不同的类别。\n",
      "2. 情感分析:判断文本表达的情感,例如判断一段文本是正面情感还是负面情感。\n",
      "3. 实体识别:识别文本中的实体,例如人名、地名、组织机构名等。\n",
      "4. 文本摘要:生成简明扼要的文本概述,通常包括文本的主题、关键词和摘要等。\n",
      "### 9.Answer:\n",
      " 1. 文本分类：将文本分类为预定义的类别，例如情感分类或主题分类。\n",
      "2. 文本摘要：生成一篇包含关键信息的文本摘要。\n",
      "3. 语言翻译：将一种语言的文本翻译成另一种语言，例如英语翻译成西班牙语。\n",
      "4. 实体抽取：利用自然语言处理从文本中抽取实体，例如名称或地点。 \n",
      "\n",
      "\n",
      "Instruction: 将以下句子从一种时态转换为另一种时态\n",
      "Input: 他正在往商店走。\n",
      "Answer: 他正在走。\n",
      "### 10.Answer:\n",
      " 他曾经往商店走过。 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "from convert_json import format_example\n",
    "\n",
    "def generate(input_text, temperature):\n",
    "    ids = tokenizer.encode(input_text)\n",
    "    input_ids = torch.LongTensor([ids])\n",
    "    out = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=300,\n",
    "        do_sample=False,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    out_text = tokenizer.decode(out[0])\n",
    "    return out_text\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, item in enumerate(instructions[:10]):\n",
    "        feature = format_example(item)\n",
    "        input_text = feature['context']\n",
    "        out_text = generate(input_text, 0)\n",
    "        answer = out_text.replace(input_text, \"\").replace(\"\\nEND\", \"\").strip()\n",
    "        item['infer_answer'] = answer\n",
    "        print(out_text)\n",
    "        print(f\"### {idx+1}.Answer:\\n\", item.get('output'), '\\n\\n')\n",
    "        answers.append({'index': idx, **item})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\dev\\ChatGLM-6B\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:1359: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你是谁 我是一个名为 ChatGLM-6B 的人工智能助手,是基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate('你是谁', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "25273a2a68c96ebac13d7fb9e0db516f9be0772777a0507fe06d682a441a3ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
